{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "704bc362-fb79-410c-884f-1370cbf55b9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Bakehouse Performance Optimization\n",
    "\n",
    "## Business Context\n",
    "\n",
    "Welcome back to **The Bakehouse**! As the franchise continues to grow, the Data Analytics team is facing new challenges. Dashboard queries that used to complete in seconds now take minutes. The monthly reporting pipeline is timing out. And the Marketing team has discovered duplicate customer records causing confusion in email campaigns.\n",
    "\n",
    "As a **Performance Engineer** at Bakehouse HQ, you've been tasked with diagnosing and resolving these performance bottlenecks while ensuring data quality across the organization.\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "You'll continue working with the Bakehouse data from `samples.bakehouse`:\n",
    "\n",
    "| Table | Description | Row Count | Usage |\n",
    "|-------|-------------|-----------|-------|\n",
    "| `sales_transactions` | Individual purchases | 3,333 | Query optimization, partitioning |\n",
    "| `sales_customers` | Customer information | 300 | Base for duplicate generation |\n",
    "| `sales_franchises` | Franchise locations | 48 | Join optimization |\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "This comprehensive lab covers four core Apache Spark performance topics:\n",
    "\n",
    "1. **Query Optimization** - Analyze execution plans, leverage Catalyst optimizer, implement predicate pushdown\n",
    "2. **Partitioning** - Understand data distribution, use repartition vs coalesce, configure shuffle partitions\n",
    "3. **De-Duplication** - Remove duplicate records, implement case-insensitive matching, standardize data formats\n",
    "4. **Integration Challenge** - Combine optimization techniques into a production-ready pipeline\n",
    "\n",
    "## Performance Journey\n",
    "\n",
    "**Act 1: Slow Dashboards** → Diagnose query performance issues and apply Catalyst optimizer techniques\n",
    "**Act 2: Scale Challenges** → Implement partitioning strategies for efficient data distribution\n",
    "**Act 3: Data Quality** → Clean duplicate customer records with advanced deduplication\n",
    "**Act 4: Production Pipeline** → Integrate all optimizations into a comprehensive reporting system\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdb15807-b44e-4e5a-8598-5de17b70047b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create a catalog for our performance lab\n",
    "CREATE CATALOG IF NOT EXISTS bakehouse_catalog;\n",
    "\n",
    "-- Create a schema (database) in the catalog\n",
    "CREATE SCHEMA IF NOT EXISTS bakehouse_catalog.performance_lab;\n",
    "\n",
    "-- Create a managed volume for file storage\n",
    "CREATE VOLUME IF NOT EXISTS bakehouse_catalog.performance_lab.workspace;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98e09ef7-2a3c-4545-ad45-de34563d462e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Volumes/bakehouse_catalog/performance_lab/workspace\n"
     ]
    }
   ],
   "source": [
    "# Set up working directory using Unity Catalog volume\n",
    "import os\n",
    "\n",
    "# Use Unity Catalog managed volume for file storage\n",
    "working_dir = \"/Volumes/bakehouse_catalog/performance_lab/workspace\"\n",
    "\n",
    "print(f\"Working directory: {working_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8be96b2-3d4c-4318-8a67-8c1eaa74e1ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned up working directory: /Volumes/bakehouse_catalog/performance_lab/workspace\n"
     ]
    }
   ],
   "source": [
    "# Clean up working directory to account for any failed previous runs.\n",
    "dbutils.fs.rm(f\"{working_dir}/transactions_partitioned\", recurse=True)\n",
    "dbutils.fs.rm(f\"{working_dir}/repartitioned_demo\", recurse=True)\n",
    "dbutils.fs.rm(f\"{working_dir}/coalesced_demo\", recurse=True)\n",
    "dbutils.fs.rm(f\"{working_dir}/customers_with_duplicates\", recurse=True)\n",
    "dbutils.fs.rm(f\"{working_dir}/customers_deduplicated\", recurse=True)\n",
    "dbutils.fs.rm(f\"{working_dir}/franchise_performance_report\", recurse=True)\n",
    "print(f\"✅ Cleaned up working directory: {working_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c33410e-d0f0-4efb-bad5-653e652b3c9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Verification Utilities\n",
    "\n",
    "These utility functions help you verify your work throughout the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14bf2773-1878-489c-adb3-eb229c1d562c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Verification utilities loaded\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "def verify_schema(df, expected_columns):\n",
    "    \"\"\"Check if DataFrame has expected columns.\"\"\"\n",
    "    missing = set(expected_columns) - set(df.columns)\n",
    "    if missing:\n",
    "        print(f\"❌ Missing columns: {missing}\")\n",
    "        return False\n",
    "    print(f\"✅ Schema correct: {len(expected_columns)} columns present\")\n",
    "    return True\n",
    "\n",
    "def check_partition_count(path, expected_count=None):\n",
    "    \"\"\"Check number of partitions in Delta table.\"\"\"\n",
    "    files = dbutils.fs.ls(path)\n",
    "    partition_count = len([f for f in files if f.name.startswith('part-')])\n",
    "    if expected_count and partition_count != expected_count:\n",
    "        print(f\"⚠️ Found {partition_count} partitions, expected {expected_count}\")\n",
    "        return False\n",
    "    print(f\"✅ Partition count: {partition_count}\")\n",
    "    return True\n",
    "\n",
    "def inspect_sample(df, num_rows=5, description=\"\"):\n",
    "    \"\"\"Display sample rows for manual inspection.\"\"\"\n",
    "    print(f\"\\n\uD83D\uDCCA Sample Data: {description}\")\n",
    "    display(df.limit(num_rows))\n",
    "    print(f\"Total rows: {df.count():,}\")\n",
    "\n",
    "print(\"✅ Verification utilities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cba7bbf9-7de0-457c-91ad-752d15b77267",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "# Section 1: Query Optimization Fundamentals\n",
    "\n",
    "**Business Goal:** Dashboard queries are taking 2+ minutes to complete. Management wants sub-second response times.\n",
    "\n",
    "In this section, you'll learn to diagnose slow queries using execution plans, understand how the Catalyst optimizer works, and implement optimization techniques like predicate pushdown and filter ordering.\n",
    "\n",
    "## Key Concepts:\n",
    "- **Catalyst Optimizer**: Spark's query optimizer that automatically improves query execution\n",
    "- **Logical Plan**: High-level description of what the query does\n",
    "- **Physical Plan**: Low-level description of how Spark will execute the query\n",
    "- **Predicate Pushdown**: Moving filters closer to the data source to reduce data transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e99fea32-8915-40a2-813a-6b80a2ef2c88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 1.1: Analyze Slow Query with Explain Plans\n",
    "\n",
    "Load the transactions data and apply multiple filters. Use the `explain()` method to view how Catalyst optimizes your query by consolidating redundant filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae9cedb4-6cdd-4de9-8ab1-7791db10a5ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n'Filter 'not('`==`('product, bread))\n+- 'Filter 'not('`==`('product, cookies))\n   +- 'Filter '`>`('totalPrice, 10)\n      +- 'Filter '`>`('totalPrice, 20)\n         +- 'UnresolvedRelation [samples, bakehouse, sales_transactions], [], false\n\n== Analyzed Logical Plan ==\ntransactionID: bigint, customerID: bigint, franchiseID: bigint, dateTime: timestamp, product: string, quantity: bigint, unitPrice: bigint, totalPrice: bigint, paymentMethod: string, cardNumber: bigint\nFilter NOT (product#16229 = bread)\n+- Filter NOT (product#16229 = cookies)\n   +- Filter (totalPrice#16232L > cast(10 as bigint))\n      +- Filter (totalPrice#16232L > cast(20 as bigint))\n         +- SubqueryAlias samples.bakehouse.sales_transactions\n            +- Relation samples.bakehouse.sales_transactions[transactionID#16225L,customerID#16226L,franchiseID#16227L,dateTime#16228,product#16229,quantity#16230L,unitPrice#16231L,totalPrice#16232L,paymentMethod#16233,cardNumber#16234L] parquet\n\n== Optimized Logical Plan ==\nFilter ((isnotnull(totalPrice#16232L) AND (totalPrice#16232L > 20)) AND NOT product#16229 IN (cookies,bread))\n+- Relation samples.bakehouse.sales_transactions[transactionID#16225L,customerID#16226L,franchiseID#16227L,dateTime#16228,product#16229,quantity#16230L,unitPrice#16231L,totalPrice#16232L,paymentMethod#16233,cardNumber#16234L] parquet\n\n== Physical Plan ==\nPhotonResultStage\n+- PhotonColumnarToRow\n   +- PhotonScan parquet samples.bakehouse.sales_transactions[transactionID#16225L,customerID#16226L,franchiseID#16227L,dateTime#16228,product#16229,quantity#16230L,unitPrice#16231L,totalPrice#16232L,paymentMethod#16233,cardNumber#16234L] DataFilters: [isnotnull(totalPrice#16232L), (totalPrice#16232L > 20), NOT product#16229 IN (cookies,bread)], DictionaryFilters: [(totalPrice#16232L > 20), NOT product#16229 IN (cookies,bread)], Format: parquet, Location: PreparedDeltaFileIndex(1 paths)[s3://system-tables-prod-us-east-2-uc-metastore-bucket/metastore/b..., OptionalDataFilters: [], PartitionFilters: [], ReadSchema: struct<transactionID:bigint,customerID:bigint,franchiseID:bigint,dateTime:timestamp,product:strin..., RequiredDataFilters: [isnotnull(totalPrice#16232L), (totalPrice#16232L > 20), NOT product#16229 IN (cookies,bread)]\n\n== Photon Explanation ==\nThe query is fully supported by Photon.\n== Optimizer Statistics (table names per statistics state) ==\n  missing = sales_transactions\n  partial = \n  full    = \nCorrective actions: consider running the following command on all tables with missing or partial statistics\n  ANALYZE TABLE <table-name> COMPUTE STATISTICS FOR ALL COLUMNS\n\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load transactions table\n",
    "# Use spark.table() to load samples.bakehouse.sales_transactions\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "transactions_df = spark.table(\"samples.bakehouse.sales_transactions\")\n",
    "\n",
    "# Apply multiple filters (some redundant)\n",
    "slow_query_df = (transactions_df\n",
    "    .filter(col(\"totalPrice\") > 20)\n",
    "    .filter(col(\"totalPrice\") > 10)  # Redundant - already filtered > 20\n",
    "    .filter(col(\"product\") != \"cookies\")\n",
    "    .filter(col(\"product\") != \"bread\")\n",
    ")\n",
    "\n",
    "# Display the logical and physical plans\n",
    "slow_query_df.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ce4c3e3-cd15-4aec-a803-020d801df55f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Task 1.1 complete: Execution plan displayed\n\uD83D\uDCDD Note: Look at the 'Optimized Logical Plan' - Catalyst consolidated the filters!\n"
     ]
    }
   ],
   "source": [
    "# CHECK YOUR WORK\n",
    "assert 'transactions_df' in dir(), \"transactions_df should be defined\"\n",
    "assert transactions_df.count() == 3333, \"Should load all 3,333 transactions\"\n",
    "print(\"✅ Task 1.1 complete: Execution plan displayed\")\n",
    "print(\"\uD83D\uDCDD Note: Look at the 'Optimized Logical Plan' - Catalyst consolidated the filters!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a41e8c63-6e83-421c-9f1c-049e99ef4d18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 1.2: Demonstrate Predicate Pushdown with Partitioned Delta\n",
    "\n",
    "Write the transactions data as a partitioned Delta table (partitioned by `franchiseID`). Then read it back with a filter and observe how Spark prunes partitions in the execution plan.\n",
    "\n",
    "**Why This Matters**: Predicate pushdown reduces data transfer by filtering at the storage layer instead of after loading all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28b0d6cd-4aaa-41a7-a539-8073a14fd0ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n'Filter '`==`('franchiseID, 3000033)\n+- Relation [transactionID#16510L,customerID#16511L,franchiseID#16512L,dateTime#16513,product#16514,quantity#16515L,unitPrice#16516L,totalPrice#16517L,paymentMethod#16518,cardNumber#16519L] parquet\n\n== Analyzed Logical Plan ==\ntransactionID: bigint, customerID: bigint, franchiseID: bigint, dateTime: timestamp, product: string, quantity: bigint, unitPrice: bigint, totalPrice: bigint, paymentMethod: string, cardNumber: bigint\nFilter (franchiseID#16512L = cast(3000033 as bigint))\n+- Relation [transactionID#16510L,customerID#16511L,franchiseID#16512L,dateTime#16513,product#16514,quantity#16515L,unitPrice#16516L,totalPrice#16517L,paymentMethod#16518,cardNumber#16519L] parquet\n\n== Optimized Logical Plan ==\nFilter (isnotnull(franchiseID#16512L) AND (franchiseID#16512L = 3000033))\n+- Relation [transactionID#16510L,customerID#16511L,franchiseID#16512L,dateTime#16513,product#16514,quantity#16515L,unitPrice#16516L,totalPrice#16517L,paymentMethod#16518,cardNumber#16519L] parquet\n\n== Physical Plan ==\nPhotonResultStage\n+- PhotonColumnarToRow\n   +- PhotonProject [transactionID#16510L, customerID#16511L, franchiseID#16512L, dateTime#16513, product#16514, quantity#16515L, unitPrice#16516L, totalPrice#16517L, paymentMethod#16518, cardNumber#16519L]\n      +- PhotonScan parquet [transactionID#16510L,customerID#16511L,dateTime#16513,product#16514,quantity#16515L,unitPrice#16516L,totalPrice#16517L,paymentMethod#16518,cardNumber#16519L,franchiseID#16512L] DataFilters: [], DictionaryFilters: [], Format: parquet, Location: PreparedDeltaFileIndex(1 paths)[dbfs:/Volumes/bakehouse_catalog/performance_lab/workspace/transac..., OptionalDataFilters: [], PartitionFilters: [isnotnull(franchiseID#16512L), (franchiseID#16512L = 3000033)], ReadSchema: struct<transactionID:bigint,customerID:bigint,dateTime:timestamp,product:string,quantity:bigint,u..., RequiredDataFilters: []\n\n== Photon Explanation ==\nThe query is fully supported by Photon.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>transactionID</th><th>customerID</th><th>franchiseID</th><th>dateTime</th><th>product</th><th>quantity</th><th>unitPrice</th><th>totalPrice</th><th>paymentMethod</th><th>cardNumber</th></tr></thead><tbody><tr><td>1002920</td><td>2000119</td><td>3000033</td><td>2024-05-07T09:08:29.107Z</td><td>Pearly Pies</td><td>10</td><td>3</td><td>30</td><td>visa</td><td>4512140833802082</td></tr><tr><td>1002951</td><td>2000072</td><td>3000033</td><td>2024-05-08T22:12:33.980Z</td><td>Tokyo Tidbits</td><td>1</td><td>3</td><td>3</td><td>visa</td><td>4517133419504961</td></tr><tr><td>1002967</td><td>2000027</td><td>3000033</td><td>2024-05-10T17:09:57.932Z</td><td>Pearly Pies</td><td>2</td><td>3</td><td>6</td><td>amex</td><td>347726165286313</td></tr><tr><td>1002987</td><td>2000093</td><td>3000033</td><td>2024-05-06T05:01:28.491Z</td><td>Austin Almond Biscotti</td><td>6</td><td>3</td><td>18</td><td>visa</td><td>4195673612785593</td></tr><tr><td>1003000</td><td>2000256</td><td>3000033</td><td>2024-05-14T20:23:44.498Z</td><td>Pearly Pies</td><td>3</td><td>3</td><td>9</td><td>amex</td><td>376481000341048</td></tr><tr><td>1003005</td><td>2000107</td><td>3000033</td><td>2024-05-15T16:52:12.463Z</td><td>Tokyo Tidbits</td><td>9</td><td>3</td><td>27</td><td>visa</td><td>4487722735852553</td></tr><tr><td>1003015</td><td>2000172</td><td>3000033</td><td>2024-05-11T04:14:23.247Z</td><td>Tokyo Tidbits</td><td>8</td><td>3</td><td>24</td><td>visa</td><td>4228081889367973</td></tr><tr><td>1003084</td><td>2000052</td><td>3000033</td><td>2024-05-02T02:06:06.463Z</td><td>Tokyo Tidbits</td><td>2</td><td>3</td><td>6</td><td>amex</td><td>345239704624095</td></tr><tr><td>1003115</td><td>2000205</td><td>3000033</td><td>2024-05-08T14:23:11.412Z</td><td>Orchard Oasis</td><td>8</td><td>3</td><td>24</td><td>mastercard</td><td>2711867627801341</td></tr><tr><td>1003128</td><td>2000293</td><td>3000033</td><td>2024-05-03T18:18:22.974Z</td><td>Tokyo Tidbits</td><td>2</td><td>3</td><td>6</td><td>visa</td><td>4776265971833366</td></tr><tr><td>1003171</td><td>2000165</td><td>3000033</td><td>2024-05-17T11:26:06.856Z</td><td>Tokyo Tidbits</td><td>3</td><td>3</td><td>9</td><td>mastercard</td><td>5594259608699990</td></tr><tr><td>1003187</td><td>2000296</td><td>3000033</td><td>2024-05-13T20:37:08.156Z</td><td>Golden Gate Ginger</td><td>1</td><td>3</td><td>3</td><td>visa</td><td>4224291392682446</td></tr><tr><td>1003256</td><td>2000084</td><td>3000033</td><td>2024-05-10T13:47:43.764Z</td><td>Orchard Oasis</td><td>10</td><td>3</td><td>30</td><td>amex</td><td>370528335469609</td></tr><tr><td>1003288</td><td>2000284</td><td>3000033</td><td>2024-05-16T23:46:27.799Z</td><td>Austin Almond Biscotti</td><td>8</td><td>3</td><td>24</td><td>mastercard</td><td>2609033592395687</td></tr><tr><td>1003299</td><td>2000059</td><td>3000033</td><td>2024-05-14T17:03:25.496Z</td><td>Austin Almond Biscotti</td><td>4</td><td>3</td><td>12</td><td>visa</td><td>4467664552271208</td></tr><tr><td>1001332</td><td>2000193</td><td>3000033</td><td>2024-05-17T01:27:50.369Z</td><td>Golden Gate Ginger</td><td>4</td><td>3</td><td>12</td><td>visa</td><td>4327604621942736</td></tr><tr><td>1001348</td><td>2000256</td><td>3000033</td><td>2024-05-08T01:43:07.553Z</td><td>Pearly Pies</td><td>7</td><td>3</td><td>21</td><td>visa</td><td>4721226896749448</td></tr><tr><td>1001374</td><td>2000005</td><td>3000033</td><td>2024-05-04T07:50:48.351Z</td><td>Orchard Oasis</td><td>7</td><td>3</td><td>21</td><td>amex</td><td>346605655356722</td></tr><tr><td>1001426</td><td>2000063</td><td>3000033</td><td>2024-05-12T17:47:46.924Z</td><td>Austin Almond Biscotti</td><td>10</td><td>3</td><td>30</td><td>visa</td><td>4369259174861376</td></tr><tr><td>1001427</td><td>2000188</td><td>3000033</td><td>2024-05-01T10:05:17.848Z</td><td>Tokyo Tidbits</td><td>2</td><td>3</td><td>6</td><td>amex</td><td>344761256528110</td></tr><tr><td>1001442</td><td>2000288</td><td>3000033</td><td>2024-05-11T12:10:36.442Z</td><td>Pearly Pies</td><td>9</td><td>3</td><td>27</td><td>mastercard</td><td>2707096608576906</td></tr><tr><td>1001458</td><td>2000034</td><td>3000033</td><td>2024-05-03T21:58:41.195Z</td><td>Orchard Oasis</td><td>2</td><td>3</td><td>6</td><td>visa</td><td>4079446070961928</td></tr><tr><td>1001459</td><td>2000026</td><td>3000033</td><td>2024-05-08T10:52:08.060Z</td><td>Austin Almond Biscotti</td><td>8</td><td>3</td><td>24</td><td>mastercard</td><td>5188368951120645</td></tr><tr><td>1001497</td><td>2000053</td><td>3000033</td><td>2024-05-11T16:07:11.925Z</td><td>Outback Oatmeal</td><td>5</td><td>3</td><td>15</td><td>mastercard</td><td>2702296543236336</td></tr><tr><td>1001509</td><td>2000152</td><td>3000033</td><td>2024-05-09T22:26:40.158Z</td><td>Austin Almond Biscotti</td><td>4</td><td>3</td><td>12</td><td>mastercard</td><td>5359816328897785</td></tr><tr><td>1001583</td><td>2000215</td><td>3000033</td><td>2024-05-07T15:24:20.000Z</td><td>Pearly Pies</td><td>2</td><td>3</td><td>6</td><td>amex</td><td>347428158399738</td></tr><tr><td>1001629</td><td>2000033</td><td>3000033</td><td>2024-05-02T09:48:53.320Z</td><td>Orchard Oasis</td><td>10</td><td>3</td><td>30</td><td>visa</td><td>4019896726721428</td></tr><tr><td>1001671</td><td>2000169</td><td>3000033</td><td>2024-05-09T03:42:20.129Z</td><td>Outback Oatmeal</td><td>10</td><td>3</td><td>30</td><td>visa</td><td>4124921301195988</td></tr><tr><td>1001704</td><td>2000255</td><td>3000033</td><td>2024-05-11T03:05:44.187Z</td><td>Orchard Oasis</td><td>10</td><td>3</td><td>30</td><td>amex</td><td>375942778841536</td></tr><tr><td>1001751</td><td>2000105</td><td>3000033</td><td>2024-05-09T01:24:33.644Z</td><td>Golden Gate Ginger</td><td>1</td><td>3</td><td>3</td><td>mastercard</td><td>5272485408550906</td></tr><tr><td>1001849</td><td>2000102</td><td>3000033</td><td>2024-05-14T14:06:49.803Z</td><td>Golden Gate Ginger</td><td>1</td><td>3</td><td>3</td><td>visa</td><td>4098673059125681</td></tr><tr><td>1001877</td><td>2000167</td><td>3000033</td><td>2024-05-03T15:01:11.776Z</td><td>Pearly Pies</td><td>8</td><td>3</td><td>24</td><td>visa</td><td>4516296595725154</td></tr><tr><td>1001939</td><td>2000167</td><td>3000033</td><td>2024-05-06T17:42:22.776Z</td><td>Tokyo Tidbits</td><td>6</td><td>3</td><td>18</td><td>visa</td><td>4776689371432414</td></tr><tr><td>1001986</td><td>2000239</td><td>3000033</td><td>2024-05-16T10:43:27.896Z</td><td>Golden Gate Ginger</td><td>4</td><td>3</td><td>12</td><td>visa</td><td>4916365980037701</td></tr><tr><td>1001997</td><td>2000088</td><td>3000033</td><td>2024-05-16T07:45:01.657Z</td><td>Golden Gate Ginger</td><td>6</td><td>3</td><td>18</td><td>amex</td><td>348330447237845</td></tr><tr><td>1002043</td><td>2000242</td><td>3000033</td><td>2024-05-04T18:21:10.722Z</td><td>Outback Oatmeal</td><td>2</td><td>3</td><td>6</td><td>visa</td><td>4882077784549142</td></tr><tr><td>1000006</td><td>2000157</td><td>3000033</td><td>2024-05-03T15:09:41.186Z</td><td>Golden Gate Ginger</td><td>7</td><td>3</td><td>21</td><td>mastercard</td><td>2264583693631006</td></tr><tr><td>1000034</td><td>2000035</td><td>3000033</td><td>2024-05-02T22:32:22.316Z</td><td>Austin Almond Biscotti</td><td>7</td><td>3</td><td>21</td><td>amex</td><td>340570657979796</td></tr><tr><td>1000041</td><td>2000117</td><td>3000033</td><td>2024-05-15T01:07:17.943Z</td><td>Pearly Pies</td><td>4</td><td>3</td><td>12</td><td>visa</td><td>4487263202484372</td></tr><tr><td>1000099</td><td>2000140</td><td>3000033</td><td>2024-05-16T08:31:45.555Z</td><td>Outback Oatmeal</td><td>3</td><td>3</td><td>9</td><td>mastercard</td><td>2709390022879113</td></tr><tr><td>1000123</td><td>2000112</td><td>3000033</td><td>2024-05-11T18:55:53.956Z</td><td>Austin Almond Biscotti</td><td>2</td><td>3</td><td>6</td><td>mastercard</td><td>5312503392430240</td></tr><tr><td>1000179</td><td>2000126</td><td>3000033</td><td>2024-05-13T01:26:51.431Z</td><td>Golden Gate Ginger</td><td>4</td><td>3</td><td>12</td><td>visa</td><td>4636315275687305</td></tr><tr><td>1000184</td><td>2000253</td><td>3000033</td><td>2024-05-13T16:47:29.644Z</td><td>Austin Almond Biscotti</td><td>6</td><td>3</td><td>18</td><td>visa</td><td>4553452341979553</td></tr><tr><td>1000263</td><td>2000232</td><td>3000033</td><td>2024-05-15T01:02:31.879Z</td><td>Tokyo Tidbits</td><td>2</td><td>3</td><td>6</td><td>mastercard</td><td>2447448446054197</td></tr><tr><td>1000362</td><td>2000113</td><td>3000033</td><td>2024-05-02T07:11:30.287Z</td><td>Pearly Pies</td><td>1</td><td>3</td><td>3</td><td>mastercard</td><td>2293074611149052</td></tr><tr><td>1000837</td><td>2000193</td><td>3000033</td><td>2024-05-01T19:55:56.100Z</td><td>Orchard Oasis</td><td>8</td><td>3</td><td>24</td><td>visa</td><td>4343238424795239</td></tr><tr><td>1000844</td><td>2000083</td><td>3000033</td><td>2024-05-13T01:52:49.481Z</td><td>Outback Oatmeal</td><td>9</td><td>3</td><td>27</td><td>mastercard</td><td>2286956558864025</td></tr><tr><td>1000855</td><td>2000147</td><td>3000033</td><td>2024-05-16T18:26:05.007Z</td><td>Austin Almond Biscotti</td><td>9</td><td>3</td><td>27</td><td>amex</td><td>345592080716038</td></tr><tr><td>1000876</td><td>2000031</td><td>3000033</td><td>2024-05-01T21:42:27.641Z</td><td>Austin Almond Biscotti</td><td>6</td><td>3</td><td>18</td><td>mastercard</td><td>2710538202452286</td></tr><tr><td>1000934</td><td>2000043</td><td>3000033</td><td>2024-05-13T06:19:23.668Z</td><td>Golden Gate Ginger</td><td>2</td><td>3</td><td>6</td><td>visa</td><td>4184282583580893</td></tr><tr><td>1001014</td><td>2000251</td><td>3000033</td><td>2024-05-10T00:12:08.920Z</td><td>Orchard Oasis</td><td>8</td><td>3</td><td>24</td><td>visa</td><td>4564211944458564</td></tr><tr><td>1001044</td><td>2000033</td><td>3000033</td><td>2024-05-12T12:36:49.574Z</td><td>Tokyo Tidbits</td><td>9</td><td>3</td><td>27</td><td>amex</td><td>346087477081376</td></tr><tr><td>1001102</td><td>2000030</td><td>3000033</td><td>2024-05-04T04:53:15.339Z</td><td>Golden Gate Ginger</td><td>8</td><td>3</td><td>24</td><td>amex</td><td>340406035529666</td></tr><tr><td>1001151</td><td>2000015</td><td>3000033</td><td>2024-05-07T12:39:28.428Z</td><td>Golden Gate Ginger</td><td>8</td><td>3</td><td>24</td><td>mastercard</td><td>5508069893065889</td></tr><tr><td>1001152</td><td>2000238</td><td>3000033</td><td>2024-05-03T16:24:13.381Z</td><td>Orchard Oasis</td><td>2</td><td>3</td><td>6</td><td>amex</td><td>378197255343749</td></tr><tr><td>1001184</td><td>2000117</td><td>3000033</td><td>2024-05-09T19:43:34.180Z</td><td>Austin Almond Biscotti</td><td>1</td><td>3</td><td>3</td><td>amex</td><td>348677732199886</td></tr><tr><td>1001212</td><td>2000193</td><td>3000033</td><td>2024-05-01T13:25:09.577Z</td><td>Orchard Oasis</td><td>9</td><td>3</td><td>27</td><td>mastercard</td><td>2707247216450170</td></tr><tr><td>1001222</td><td>2000241</td><td>3000033</td><td>2024-05-04T15:46:51.983Z</td><td>Pearly Pies</td><td>2</td><td>3</td><td>6</td><td>visa</td><td>4598384841656703</td></tr><tr><td>1001231</td><td>2000166</td><td>3000033</td><td>2024-05-15T03:48:58.314Z</td><td>Austin Almond Biscotti</td><td>4</td><td>3</td><td>12</td><td>visa</td><td>4787407341051868</td></tr><tr><td>1002167</td><td>2000119</td><td>3000033</td><td>2024-05-08T20:24:42.350Z</td><td>Tokyo Tidbits</td><td>4</td><td>3</td><td>12</td><td>visa</td><td>4163172975333651</td></tr><tr><td>1002171</td><td>2000074</td><td>3000033</td><td>2024-05-05T05:50:49.938Z</td><td>Tokyo Tidbits</td><td>8</td><td>3</td><td>24</td><td>amex</td><td>378768825670942</td></tr><tr><td>1002278</td><td>2000221</td><td>3000033</td><td>2024-05-05T12:09:54.987Z</td><td>Outback Oatmeal</td><td>9</td><td>3</td><td>27</td><td>mastercard</td><td>2237943174558066</td></tr><tr><td>1002294</td><td>2000225</td><td>3000033</td><td>2024-05-13T00:24:08.673Z</td><td>Outback Oatmeal</td><td>10</td><td>3</td><td>30</td><td>visa</td><td>4353273881752339</td></tr><tr><td>1002411</td><td>2000269</td><td>3000033</td><td>2024-05-14T13:06:47.257Z</td><td>Golden Gate Ginger</td><td>8</td><td>3</td><td>24</td><td>amex</td><td>377549944359224</td></tr><tr><td>1002412</td><td>2000290</td><td>3000033</td><td>2024-05-15T03:40:23.447Z</td><td>Austin Almond Biscotti</td><td>4</td><td>3</td><td>12</td><td>amex</td><td>372232432118098</td></tr><tr><td>1002527</td><td>2000185</td><td>3000033</td><td>2024-05-05T03:28:21.357Z</td><td>Pearly Pies</td><td>8</td><td>3</td><td>24</td><td>mastercard</td><td>2517530647737699</td></tr><tr><td>1002622</td><td>2000249</td><td>3000033</td><td>2024-05-10T23:28:32.669Z</td><td>Golden Gate Ginger</td><td>3</td><td>3</td><td>9</td><td>amex</td><td>372150676711511</td></tr><tr><td>1002643</td><td>2000073</td><td>3000033</td><td>2024-05-09T22:52:22.889Z</td><td>Golden Gate Ginger</td><td>6</td><td>3</td><td>18</td><td>amex</td><td>373601478527173</td></tr><tr><td>1002663</td><td>2000173</td><td>3000033</td><td>2024-05-15T17:41:53.365Z</td><td>Pearly Pies</td><td>5</td><td>3</td><td>15</td><td>mastercard</td><td>5599856254505085</td></tr><tr><td>1002671</td><td>2000142</td><td>3000033</td><td>2024-05-08T06:30:09.304Z</td><td>Pearly Pies</td><td>5</td><td>3</td><td>15</td><td>amex</td><td>374615882200069</td></tr><tr><td>1002682</td><td>2000205</td><td>3000033</td><td>2024-05-15T09:45:07.291Z</td><td>Orchard Oasis</td><td>8</td><td>3</td><td>24</td><td>mastercard</td><td>2708775490617774</td></tr><tr><td>1002705</td><td>2000213</td><td>3000033</td><td>2024-05-09T08:07:13.645Z</td><td>Outback Oatmeal</td><td>1</td><td>3</td><td>3</td><td>visa</td><td>4178864965773689</td></tr><tr><td>1002733</td><td>2000189</td><td>3000033</td><td>2024-05-06T01:38:04.857Z</td><td>Austin Almond Biscotti</td><td>4</td><td>3</td><td>12</td><td>visa</td><td>4608857253297239</td></tr><tr><td>1002844</td><td>2000119</td><td>3000033</td><td>2024-05-13T14:30:25.511Z</td><td>Tokyo Tidbits</td><td>9</td><td>3</td><td>27</td><td>mastercard</td><td>2276181161152930</td></tr><tr><td>1000463</td><td>2000272</td><td>3000033</td><td>2024-05-01T05:03:14.129Z</td><td>Golden Gate Ginger</td><td>8</td><td>3</td><td>24</td><td>visa</td><td>4300459813129282</td></tr><tr><td>1000502</td><td>2000107</td><td>3000033</td><td>2024-05-11T13:07:16.135Z</td><td>Tokyo Tidbits</td><td>5</td><td>3</td><td>15</td><td>amex</td><td>342002388622147</td></tr><tr><td>1000531</td><td>2000190</td><td>3000033</td><td>2024-05-03T06:05:16.390Z</td><td>Outback Oatmeal</td><td>10</td><td>3</td><td>30</td><td>mastercard</td><td>2365793636251444</td></tr><tr><td>1000558</td><td>2000088</td><td>3000033</td><td>2024-05-02T15:55:25.944Z</td><td>Outback Oatmeal</td><td>9</td><td>3</td><td>27</td><td>visa</td><td>4773496306637676</td></tr><tr><td>1000590</td><td>2000203</td><td>3000033</td><td>2024-05-09T18:09:42.971Z</td><td>Tokyo Tidbits</td><td>6</td><td>3</td><td>18</td><td>mastercard</td><td>2279423821096108</td></tr><tr><td>1000631</td><td>2000016</td><td>3000033</td><td>2024-05-03T18:25:15.599Z</td><td>Outback Oatmeal</td><td>8</td><td>3</td><td>24</td><td>mastercard</td><td>2639944057781936</td></tr><tr><td>1000648</td><td>2000297</td><td>3000033</td><td>2024-05-14T14:23:16.665Z</td><td>Tokyo Tidbits</td><td>3</td><td>3</td><td>9</td><td>visa</td><td>4717939806776360</td></tr><tr><td>1000661</td><td>2000101</td><td>3000033</td><td>2024-05-11T13:34:48.996Z</td><td>Golden Gate Ginger</td><td>7</td><td>3</td><td>21</td><td>amex</td><td>379189571059652</td></tr><tr><td>1000688</td><td>2000185</td><td>3000033</td><td>2024-05-12T15:55:06.302Z</td><td>Tokyo Tidbits</td><td>6</td><td>3</td><td>18</td><td>amex</td><td>343800174623255</td></tr><tr><td>1000715</td><td>2000299</td><td>3000033</td><td>2024-05-09T04:11:54.099Z</td><td>Golden Gate Ginger</td><td>2</td><td>3</td><td>6</td><td>amex</td><td>377496441952830</td></tr><tr><td>1000736</td><td>2000190</td><td>3000033</td><td>2024-05-12T14:48:55.750Z</td><td>Orchard Oasis</td><td>5</td><td>3</td><td>15</td><td>amex</td><td>375721229380397</td></tr><tr><td>1000748</td><td>2000296</td><td>3000033</td><td>2024-05-16T21:32:16.865Z</td><td>Pearly Pies</td><td>3</td><td>3</td><td>9</td><td>amex</td><td>348364134510420</td></tr><tr><td>1000750</td><td>2000150</td><td>3000033</td><td>2024-05-09T16:08:40.493Z</td><td>Pearly Pies</td><td>10</td><td>3</td><td>30</td><td>visa</td><td>4683974525798890</td></tr><tr><td>1000758</td><td>2000148</td><td>3000033</td><td>2024-05-02T21:39:01.993Z</td><td>Orchard Oasis</td><td>1</td><td>3</td><td>3</td><td>mastercard</td><td>2291808848866430</td></tr><tr><td>1000771</td><td>2000029</td><td>3000033</td><td>2024-05-07T05:28:44.901Z</td><td>Tokyo Tidbits</td><td>1</td><td>3</td><td>3</td><td>mastercard</td><td>2687192418380706</td></tr><tr><td>1000798</td><td>2000137</td><td>3000033</td><td>2024-05-17T08:39:07.682Z</td><td>Orchard Oasis</td><td>2</td><td>3</td><td>6</td><td>mastercard</td><td>2707658352581216</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1002920,
         2000119,
         3000033,
         "2024-05-07T09:08:29.107Z",
         "Pearly Pies",
         10,
         3,
         30,
         "visa",
         4512140833802082
        ],
        [
         1002951,
         2000072,
         3000033,
         "2024-05-08T22:12:33.980Z",
         "Tokyo Tidbits",
         1,
         3,
         3,
         "visa",
         4517133419504961
        ],
        [
         1002967,
         2000027,
         3000033,
         "2024-05-10T17:09:57.932Z",
         "Pearly Pies",
         2,
         3,
         6,
         "amex",
         347726165286313
        ],
        [
         1002987,
         2000093,
         3000033,
         "2024-05-06T05:01:28.491Z",
         "Austin Almond Biscotti",
         6,
         3,
         18,
         "visa",
         4195673612785593
        ],
        [
         1003000,
         2000256,
         3000033,
         "2024-05-14T20:23:44.498Z",
         "Pearly Pies",
         3,
         3,
         9,
         "amex",
         376481000341048
        ],
        [
         1003005,
         2000107,
         3000033,
         "2024-05-15T16:52:12.463Z",
         "Tokyo Tidbits",
         9,
         3,
         27,
         "visa",
         4487722735852553
        ],
        [
         1003015,
         2000172,
         3000033,
         "2024-05-11T04:14:23.247Z",
         "Tokyo Tidbits",
         8,
         3,
         24,
         "visa",
         4228081889367973
        ],
        [
         1003084,
         2000052,
         3000033,
         "2024-05-02T02:06:06.463Z",
         "Tokyo Tidbits",
         2,
         3,
         6,
         "amex",
         345239704624095
        ],
        [
         1003115,
         2000205,
         3000033,
         "2024-05-08T14:23:11.412Z",
         "Orchard Oasis",
         8,
         3,
         24,
         "mastercard",
         2711867627801341
        ],
        [
         1003128,
         2000293,
         3000033,
         "2024-05-03T18:18:22.974Z",
         "Tokyo Tidbits",
         2,
         3,
         6,
         "visa",
         4776265971833366
        ],
        [
         1003171,
         2000165,
         3000033,
         "2024-05-17T11:26:06.856Z",
         "Tokyo Tidbits",
         3,
         3,
         9,
         "mastercard",
         5594259608699990
        ],
        [
         1003187,
         2000296,
         3000033,
         "2024-05-13T20:37:08.156Z",
         "Golden Gate Ginger",
         1,
         3,
         3,
         "visa",
         4224291392682446
        ],
        [
         1003256,
         2000084,
         3000033,
         "2024-05-10T13:47:43.764Z",
         "Orchard Oasis",
         10,
         3,
         30,
         "amex",
         370528335469609
        ],
        [
         1003288,
         2000284,
         3000033,
         "2024-05-16T23:46:27.799Z",
         "Austin Almond Biscotti",
         8,
         3,
         24,
         "mastercard",
         2609033592395687
        ],
        [
         1003299,
         2000059,
         3000033,
         "2024-05-14T17:03:25.496Z",
         "Austin Almond Biscotti",
         4,
         3,
         12,
         "visa",
         4467664552271208
        ],
        [
         1001332,
         2000193,
         3000033,
         "2024-05-17T01:27:50.369Z",
         "Golden Gate Ginger",
         4,
         3,
         12,
         "visa",
         4327604621942736
        ],
        [
         1001348,
         2000256,
         3000033,
         "2024-05-08T01:43:07.553Z",
         "Pearly Pies",
         7,
         3,
         21,
         "visa",
         4721226896749448
        ],
        [
         1001374,
         2000005,
         3000033,
         "2024-05-04T07:50:48.351Z",
         "Orchard Oasis",
         7,
         3,
         21,
         "amex",
         346605655356722
        ],
        [
         1001426,
         2000063,
         3000033,
         "2024-05-12T17:47:46.924Z",
         "Austin Almond Biscotti",
         10,
         3,
         30,
         "visa",
         4369259174861376
        ],
        [
         1001427,
         2000188,
         3000033,
         "2024-05-01T10:05:17.848Z",
         "Tokyo Tidbits",
         2,
         3,
         6,
         "amex",
         344761256528110
        ],
        [
         1001442,
         2000288,
         3000033,
         "2024-05-11T12:10:36.442Z",
         "Pearly Pies",
         9,
         3,
         27,
         "mastercard",
         2707096608576906
        ],
        [
         1001458,
         2000034,
         3000033,
         "2024-05-03T21:58:41.195Z",
         "Orchard Oasis",
         2,
         3,
         6,
         "visa",
         4079446070961928
        ],
        [
         1001459,
         2000026,
         3000033,
         "2024-05-08T10:52:08.060Z",
         "Austin Almond Biscotti",
         8,
         3,
         24,
         "mastercard",
         5188368951120645
        ],
        [
         1001497,
         2000053,
         3000033,
         "2024-05-11T16:07:11.925Z",
         "Outback Oatmeal",
         5,
         3,
         15,
         "mastercard",
         2702296543236336
        ],
        [
         1001509,
         2000152,
         3000033,
         "2024-05-09T22:26:40.158Z",
         "Austin Almond Biscotti",
         4,
         3,
         12,
         "mastercard",
         5359816328897785
        ],
        [
         1001583,
         2000215,
         3000033,
         "2024-05-07T15:24:20.000Z",
         "Pearly Pies",
         2,
         3,
         6,
         "amex",
         347428158399738
        ],
        [
         1001629,
         2000033,
         3000033,
         "2024-05-02T09:48:53.320Z",
         "Orchard Oasis",
         10,
         3,
         30,
         "visa",
         4019896726721428
        ],
        [
         1001671,
         2000169,
         3000033,
         "2024-05-09T03:42:20.129Z",
         "Outback Oatmeal",
         10,
         3,
         30,
         "visa",
         4124921301195988
        ],
        [
         1001704,
         2000255,
         3000033,
         "2024-05-11T03:05:44.187Z",
         "Orchard Oasis",
         10,
         3,
         30,
         "amex",
         375942778841536
        ],
        [
         1001751,
         2000105,
         3000033,
         "2024-05-09T01:24:33.644Z",
         "Golden Gate Ginger",
         1,
         3,
         3,
         "mastercard",
         5272485408550906
        ],
        [
         1001849,
         2000102,
         3000033,
         "2024-05-14T14:06:49.803Z",
         "Golden Gate Ginger",
         1,
         3,
         3,
         "visa",
         4098673059125681
        ],
        [
         1001877,
         2000167,
         3000033,
         "2024-05-03T15:01:11.776Z",
         "Pearly Pies",
         8,
         3,
         24,
         "visa",
         4516296595725154
        ],
        [
         1001939,
         2000167,
         3000033,
         "2024-05-06T17:42:22.776Z",
         "Tokyo Tidbits",
         6,
         3,
         18,
         "visa",
         4776689371432414
        ],
        [
         1001986,
         2000239,
         3000033,
         "2024-05-16T10:43:27.896Z",
         "Golden Gate Ginger",
         4,
         3,
         12,
         "visa",
         4916365980037701
        ],
        [
         1001997,
         2000088,
         3000033,
         "2024-05-16T07:45:01.657Z",
         "Golden Gate Ginger",
         6,
         3,
         18,
         "amex",
         348330447237845
        ],
        [
         1002043,
         2000242,
         3000033,
         "2024-05-04T18:21:10.722Z",
         "Outback Oatmeal",
         2,
         3,
         6,
         "visa",
         4882077784549142
        ],
        [
         1000006,
         2000157,
         3000033,
         "2024-05-03T15:09:41.186Z",
         "Golden Gate Ginger",
         7,
         3,
         21,
         "mastercard",
         2264583693631006
        ],
        [
         1000034,
         2000035,
         3000033,
         "2024-05-02T22:32:22.316Z",
         "Austin Almond Biscotti",
         7,
         3,
         21,
         "amex",
         340570657979796
        ],
        [
         1000041,
         2000117,
         3000033,
         "2024-05-15T01:07:17.943Z",
         "Pearly Pies",
         4,
         3,
         12,
         "visa",
         4487263202484372
        ],
        [
         1000099,
         2000140,
         3000033,
         "2024-05-16T08:31:45.555Z",
         "Outback Oatmeal",
         3,
         3,
         9,
         "mastercard",
         2709390022879113
        ],
        [
         1000123,
         2000112,
         3000033,
         "2024-05-11T18:55:53.956Z",
         "Austin Almond Biscotti",
         2,
         3,
         6,
         "mastercard",
         5312503392430240
        ],
        [
         1000179,
         2000126,
         3000033,
         "2024-05-13T01:26:51.431Z",
         "Golden Gate Ginger",
         4,
         3,
         12,
         "visa",
         4636315275687305
        ],
        [
         1000184,
         2000253,
         3000033,
         "2024-05-13T16:47:29.644Z",
         "Austin Almond Biscotti",
         6,
         3,
         18,
         "visa",
         4553452341979553
        ],
        [
         1000263,
         2000232,
         3000033,
         "2024-05-15T01:02:31.879Z",
         "Tokyo Tidbits",
         2,
         3,
         6,
         "mastercard",
         2447448446054197
        ],
        [
         1000362,
         2000113,
         3000033,
         "2024-05-02T07:11:30.287Z",
         "Pearly Pies",
         1,
         3,
         3,
         "mastercard",
         2293074611149052
        ],
        [
         1000837,
         2000193,
         3000033,
         "2024-05-01T19:55:56.100Z",
         "Orchard Oasis",
         8,
         3,
         24,
         "visa",
         4343238424795239
        ],
        [
         1000844,
         2000083,
         3000033,
         "2024-05-13T01:52:49.481Z",
         "Outback Oatmeal",
         9,
         3,
         27,
         "mastercard",
         2286956558864025
        ],
        [
         1000855,
         2000147,
         3000033,
         "2024-05-16T18:26:05.007Z",
         "Austin Almond Biscotti",
         9,
         3,
         27,
         "amex",
         345592080716038
        ],
        [
         1000876,
         2000031,
         3000033,
         "2024-05-01T21:42:27.641Z",
         "Austin Almond Biscotti",
         6,
         3,
         18,
         "mastercard",
         2710538202452286
        ],
        [
         1000934,
         2000043,
         3000033,
         "2024-05-13T06:19:23.668Z",
         "Golden Gate Ginger",
         2,
         3,
         6,
         "visa",
         4184282583580893
        ],
        [
         1001014,
         2000251,
         3000033,
         "2024-05-10T00:12:08.920Z",
         "Orchard Oasis",
         8,
         3,
         24,
         "visa",
         4564211944458564
        ],
        [
         1001044,
         2000033,
         3000033,
         "2024-05-12T12:36:49.574Z",
         "Tokyo Tidbits",
         9,
         3,
         27,
         "amex",
         346087477081376
        ],
        [
         1001102,
         2000030,
         3000033,
         "2024-05-04T04:53:15.339Z",
         "Golden Gate Ginger",
         8,
         3,
         24,
         "amex",
         340406035529666
        ],
        [
         1001151,
         2000015,
         3000033,
         "2024-05-07T12:39:28.428Z",
         "Golden Gate Ginger",
         8,
         3,
         24,
         "mastercard",
         5508069893065889
        ],
        [
         1001152,
         2000238,
         3000033,
         "2024-05-03T16:24:13.381Z",
         "Orchard Oasis",
         2,
         3,
         6,
         "amex",
         378197255343749
        ],
        [
         1001184,
         2000117,
         3000033,
         "2024-05-09T19:43:34.180Z",
         "Austin Almond Biscotti",
         1,
         3,
         3,
         "amex",
         348677732199886
        ],
        [
         1001212,
         2000193,
         3000033,
         "2024-05-01T13:25:09.577Z",
         "Orchard Oasis",
         9,
         3,
         27,
         "mastercard",
         2707247216450170
        ],
        [
         1001222,
         2000241,
         3000033,
         "2024-05-04T15:46:51.983Z",
         "Pearly Pies",
         2,
         3,
         6,
         "visa",
         4598384841656703
        ],
        [
         1001231,
         2000166,
         3000033,
         "2024-05-15T03:48:58.314Z",
         "Austin Almond Biscotti",
         4,
         3,
         12,
         "visa",
         4787407341051868
        ],
        [
         1002167,
         2000119,
         3000033,
         "2024-05-08T20:24:42.350Z",
         "Tokyo Tidbits",
         4,
         3,
         12,
         "visa",
         4163172975333651
        ],
        [
         1002171,
         2000074,
         3000033,
         "2024-05-05T05:50:49.938Z",
         "Tokyo Tidbits",
         8,
         3,
         24,
         "amex",
         378768825670942
        ],
        [
         1002278,
         2000221,
         3000033,
         "2024-05-05T12:09:54.987Z",
         "Outback Oatmeal",
         9,
         3,
         27,
         "mastercard",
         2237943174558066
        ],
        [
         1002294,
         2000225,
         3000033,
         "2024-05-13T00:24:08.673Z",
         "Outback Oatmeal",
         10,
         3,
         30,
         "visa",
         4353273881752339
        ],
        [
         1002411,
         2000269,
         3000033,
         "2024-05-14T13:06:47.257Z",
         "Golden Gate Ginger",
         8,
         3,
         24,
         "amex",
         377549944359224
        ],
        [
         1002412,
         2000290,
         3000033,
         "2024-05-15T03:40:23.447Z",
         "Austin Almond Biscotti",
         4,
         3,
         12,
         "amex",
         372232432118098
        ],
        [
         1002527,
         2000185,
         3000033,
         "2024-05-05T03:28:21.357Z",
         "Pearly Pies",
         8,
         3,
         24,
         "mastercard",
         2517530647737699
        ],
        [
         1002622,
         2000249,
         3000033,
         "2024-05-10T23:28:32.669Z",
         "Golden Gate Ginger",
         3,
         3,
         9,
         "amex",
         372150676711511
        ],
        [
         1002643,
         2000073,
         3000033,
         "2024-05-09T22:52:22.889Z",
         "Golden Gate Ginger",
         6,
         3,
         18,
         "amex",
         373601478527173
        ],
        [
         1002663,
         2000173,
         3000033,
         "2024-05-15T17:41:53.365Z",
         "Pearly Pies",
         5,
         3,
         15,
         "mastercard",
         5599856254505085
        ],
        [
         1002671,
         2000142,
         3000033,
         "2024-05-08T06:30:09.304Z",
         "Pearly Pies",
         5,
         3,
         15,
         "amex",
         374615882200069
        ],
        [
         1002682,
         2000205,
         3000033,
         "2024-05-15T09:45:07.291Z",
         "Orchard Oasis",
         8,
         3,
         24,
         "mastercard",
         2708775490617774
        ],
        [
         1002705,
         2000213,
         3000033,
         "2024-05-09T08:07:13.645Z",
         "Outback Oatmeal",
         1,
         3,
         3,
         "visa",
         4178864965773689
        ],
        [
         1002733,
         2000189,
         3000033,
         "2024-05-06T01:38:04.857Z",
         "Austin Almond Biscotti",
         4,
         3,
         12,
         "visa",
         4608857253297239
        ],
        [
         1002844,
         2000119,
         3000033,
         "2024-05-13T14:30:25.511Z",
         "Tokyo Tidbits",
         9,
         3,
         27,
         "mastercard",
         2276181161152930
        ],
        [
         1000463,
         2000272,
         3000033,
         "2024-05-01T05:03:14.129Z",
         "Golden Gate Ginger",
         8,
         3,
         24,
         "visa",
         4300459813129282
        ],
        [
         1000502,
         2000107,
         3000033,
         "2024-05-11T13:07:16.135Z",
         "Tokyo Tidbits",
         5,
         3,
         15,
         "amex",
         342002388622147
        ],
        [
         1000531,
         2000190,
         3000033,
         "2024-05-03T06:05:16.390Z",
         "Outback Oatmeal",
         10,
         3,
         30,
         "mastercard",
         2365793636251444
        ],
        [
         1000558,
         2000088,
         3000033,
         "2024-05-02T15:55:25.944Z",
         "Outback Oatmeal",
         9,
         3,
         27,
         "visa",
         4773496306637676
        ],
        [
         1000590,
         2000203,
         3000033,
         "2024-05-09T18:09:42.971Z",
         "Tokyo Tidbits",
         6,
         3,
         18,
         "mastercard",
         2279423821096108
        ],
        [
         1000631,
         2000016,
         3000033,
         "2024-05-03T18:25:15.599Z",
         "Outback Oatmeal",
         8,
         3,
         24,
         "mastercard",
         2639944057781936
        ],
        [
         1000648,
         2000297,
         3000033,
         "2024-05-14T14:23:16.665Z",
         "Tokyo Tidbits",
         3,
         3,
         9,
         "visa",
         4717939806776360
        ],
        [
         1000661,
         2000101,
         3000033,
         "2024-05-11T13:34:48.996Z",
         "Golden Gate Ginger",
         7,
         3,
         21,
         "amex",
         379189571059652
        ],
        [
         1000688,
         2000185,
         3000033,
         "2024-05-12T15:55:06.302Z",
         "Tokyo Tidbits",
         6,
         3,
         18,
         "amex",
         343800174623255
        ],
        [
         1000715,
         2000299,
         3000033,
         "2024-05-09T04:11:54.099Z",
         "Golden Gate Ginger",
         2,
         3,
         6,
         "amex",
         377496441952830
        ],
        [
         1000736,
         2000190,
         3000033,
         "2024-05-12T14:48:55.750Z",
         "Orchard Oasis",
         5,
         3,
         15,
         "amex",
         375721229380397
        ],
        [
         1000748,
         2000296,
         3000033,
         "2024-05-16T21:32:16.865Z",
         "Pearly Pies",
         3,
         3,
         9,
         "amex",
         348364134510420
        ],
        [
         1000750,
         2000150,
         3000033,
         "2024-05-09T16:08:40.493Z",
         "Pearly Pies",
         10,
         3,
         30,
         "visa",
         4683974525798890
        ],
        [
         1000758,
         2000148,
         3000033,
         "2024-05-02T21:39:01.993Z",
         "Orchard Oasis",
         1,
         3,
         3,
         "mastercard",
         2291808848866430
        ],
        [
         1000771,
         2000029,
         3000033,
         "2024-05-07T05:28:44.901Z",
         "Tokyo Tidbits",
         1,
         3,
         3,
         "mastercard",
         2687192418380706
        ],
        [
         1000798,
         2000137,
         3000033,
         "2024-05-17T08:39:07.682Z",
         "Orchard Oasis",
         2,
         3,
         6,
         "mastercard",
         2707658352581216
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "transactionID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "customerID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "franchiseID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "dateTime",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "product",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "quantity",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "unitPrice",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "totalPrice",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "paymentMethod",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cardNumber",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Write partitioned Delta table and read with filter\n",
    "# 1. Partition by \"franchiseID\" column\n",
    "# 2. Filter for franchiseID == 3000033 when reading back\n",
    "\n",
    "(transactions_df\n",
    " .write\n",
    " .partitionBy(\"franchiseID\")  # Which column to partition by?\n",
    " .format(\"delta\")\n",
    " .mode(\"overwrite\")\n",
    " .save(f\"{working_dir}/transactions_partitioned\")\n",
    ")\n",
    "\n",
    "# Read with filter - Spark will only read relevant partitions\n",
    "filtered_df = spark.read.format(\"delta\").load(\n",
    "    f\"{working_dir}/transactions_partitioned\"\n",
    ").filter(col(\"franchiseID\") == 3000033)  # Filter condition: col(\"franchiseID\") == 3000033\n",
    "\n",
    "# Display the execution plan\n",
    "filtered_df.explain(True)\n",
    "\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22edfee7-0fd3-4d96-8741-cabfdc088ba1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Task 1.2 complete: Filtered to 90 transactions with partition pruning\n\uD83D\uDCDD Look at the explain plan output above - you should see PartitionFilters showing Spark pruned partitions!\n"
     ]
    }
   ],
   "source": [
    "# CHECK YOUR WORK\n",
    "assert filtered_df.count() > 0, \"Should have results for franchiseID = 3000033\"\n",
    "print(f\"✅ Task 1.2 complete: Filtered to {filtered_df.count()} transactions with partition pruning\")\n",
    "print(\"\uD83D\uDCDD Look at the explain plan output above - you should see PartitionFilters showing Spark pruned partitions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a3ad619-5b3f-46f4-a68d-a2e33fa3c972",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 1.3: Optimize Join Query with Filter Pushdown\n",
    "\n",
    "Compare two approaches:\n",
    "1. **Inefficient**: Join first, then filter\n",
    "2. **Efficient**: Filter before join\n",
    "\n",
    "Observe the dramatic difference in rows processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45d2be67-0dd2-4b55-937f-3876a3d011c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inefficient approach processes 3333 transactions\nFiltered result: 1124 rows\n\nEfficient approach joins with only 16 franchises\nSame filtered result: 1124 rows\n"
     ]
    }
   ],
   "source": [
    "# Load franchises data\n",
    "franchises_df = spark.table(\"samples.bakehouse.sales_franchises\")\n",
    "\n",
    "# INEFFICIENT APPROACH: Join then filter\n",
    "slow_join_df = (transactions_df\n",
    "    .join(franchises_df, \"franchiseID\")\n",
    "    .filter(col(\"country\") == \"US\")\n",
    ")\n",
    "\n",
    "print(f\"Inefficient approach processes {transactions_df.count()} transactions\")\n",
    "print(f\"Filtered result: {slow_join_df.count()} rows\")\n",
    "\n",
    "# TODO: Optimize join by filtering before joining\n",
    "# 1. Filter franchises_df where country == \"USA\"\n",
    "# 2. Join transactions_df with filtered franchises on \"franchiseID\"\n",
    "\n",
    "fast_franchises_df = franchises_df.filter(col(\"country\") == \"US\")  # Filter condition for USA\n",
    "fast_join_df = transactions_df.join(fast_franchises_df, \"franchiseID\")  # Join with filtered DataFrame, join column\n",
    "\n",
    "print(f\"\\nEfficient approach joins with only {fast_franchises_df.count()} franchises\")\n",
    "print(f\"Same filtered result: {fast_join_df.count()} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7805952-ca49-45f4-8abd-a13e088de439",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Task 1.3 complete: Join optimization demonstrated\n\uD83D\uDCCA Efficiency gain: Reduced franchise table from 48 to 16 rows before join\n"
     ]
    }
   ],
   "source": [
    "# CHECK YOUR WORK\n",
    "assert slow_join_df.count() == fast_join_df.count(), \"Both approaches should return same results\"\n",
    "assert fast_franchises_df.count() < franchises_df.count(), \"Should filter franchises before join\"\n",
    "print(\"✅ Task 1.3 complete: Join optimization demonstrated\")\n",
    "print(f\"\uD83D\uDCCA Efficiency gain: Reduced franchise table from {franchises_df.count()} to {fast_franchises_df.count()} rows before join\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "934bbe5d-7a0b-466f-8148-c4471346b21b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "# Section 2: Partitioning for Performance\n",
    "\n",
    "**Business Goal:** As data grows, queries are slowing down. We need to distribute workload efficiently across our cluster.\n",
    "\n",
    "In this section, you'll learn to inspect partition counts, use repartition vs coalesce, configure shuffle partitions, and leverage Adaptive Query Execution (AQE).\n",
    "\n",
    "## Key Concepts:\n",
    "- **Partition**: A chunk of data distributed across the cluster\n",
    "- **repartition()**: Full shuffle to create evenly balanced partitions\n",
    "- **coalesce()**: Narrow transformation to reduce partitions without full shuffle\n",
    "- **Shuffle Partitions**: Number of partitions created during wide transformations (joins, aggregations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37e55d5d-aa3d-4442-a1e1-e97d93d66a1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 2.1: Repartition for Balanced Distribution\n",
    "\n",
    "Use `repartition()` to redistribute data evenly across 8 partitions. This performs a full shuffle. We'll verify by writing the data and counting output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4764a79-6a1d-4b9a-a45a-dc016c302111",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files created: 8\n→ Each partition writes one file, so we have 8 partitions\n"
     ]
    }
   ],
   "source": [
    "# TODO: Repartition to 8 partitions\n",
    "# Use .repartition(8) method on transactions_df\n",
    "\n",
    "repartitioned_df = transactions_df.repartition(8)\n",
    "\n",
    "# Write to verify partition count through file output\n",
    "(repartitioned_df\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .format(\"delta\")\n",
    " .save(f\"{working_dir}/repartitioned_demo\")\n",
    ")\n",
    "\n",
    "# Count the data files (each partition creates one file)\n",
    "output_files = dbutils.fs.ls(f\"{working_dir}/repartitioned_demo\")\n",
    "data_files = [f for f in output_files if f.name.endswith('.parquet')]\n",
    "print(f\"Output files created: {len(data_files)}\")\n",
    "print(f\"→ Each partition writes one file, so we have {len(data_files)} partitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce0e1a2d-e9ae-41fb-bd5d-6d37e6eef8f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Task 2.1 complete: Repartitioned to 8 partitions\n\uD83D\uDCDD Note: repartition() triggers a full shuffle but ensures even distribution\n"
     ]
    }
   ],
   "source": [
    "# CHECK YOUR WORK\n",
    "assert len(data_files) == 8, f\"Should have exactly 8 files (partitions), got {len(data_files)}\"\n",
    "reloaded_count = spark.read.format(\"delta\").load(f\"{working_dir}/repartitioned_demo\").count()\n",
    "assert reloaded_count == transactions_df.count(), \"Row count should remain the same\"\n",
    "print(\"✅ Task 2.1 complete: Repartitioned to 8 partitions\")\n",
    "print(\"\uD83D\uDCDD Note: repartition() triggers a full shuffle but ensures even distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c89eaf3-8ba8-4196-9be3-262e9c5ba09f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 2.2: Coalesce for Narrow Transformation\n",
    "\n",
    "Use `coalesce()` to reduce partitions without a full shuffle. Observe the key difference: coalesce is efficient but cannot increase partition count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "440db668-22c0-4210-9321-9c49393550d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After coalesce(2): 1 files (partitions)\n→ Reduced from 8 to 1 partitions without full shuffle!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Coalesce to reduce partitions\n",
    "# Use .coalesce(2) method to reduce to 2 partitions\n",
    "\n",
    "# Load the repartitioned data from Task 2.1\n",
    "base_df = spark.read.format(\"delta\").load(f\"{working_dir}/repartitioned_demo\")\n",
    "\n",
    "coalesced_df = base_df.coalesce(2)\n",
    "\n",
    "# Write and verify\n",
    "(coalesced_df\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .format(\"delta\")\n",
    " .save(f\"{working_dir}/coalesced_demo\")\n",
    ")\n",
    "\n",
    "output_files = dbutils.fs.ls(f\"{working_dir}/coalesced_demo\")\n",
    "data_files = [f for f in output_files if f.name.endswith('.parquet')]\n",
    "print(f\"After coalesce(2): {len(data_files)} files (partitions)\")\n",
    "print(f\"→ Reduced from 8 to {len(data_files)} partitions without full shuffle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14277f7f-bbaf-4999-8982-6487d3546402",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Task 2.2 complete: Coalesce behavior understood\n\uD83D\uDCDD Use coalesce() to reduce partitions cheaply, repartition() to increase or rebalance\n\uD83D\uDCA1 Note: With small datasets, Delta may optimize to fewer files than the coalesce number\n"
     ]
    }
   ],
   "source": [
    "# CHECK YOUR WORK\n",
    "assert len(data_files) <= 2, f\"Should have at most 2 files (partitions), got {len(data_files)}\"\n",
    "assert len(data_files) < 8, f\"Should have fewer files than before repartitioning (8), got {len(data_files)}\"\n",
    "assert coalesced_df.count() == base_df.count(), \"Row count should remain the same\"\n",
    "print(\"✅ Task 2.2 complete: Coalesce behavior understood\")\n",
    "print(\"\uD83D\uDCDD Use coalesce() to reduce partitions cheaply, repartition() to increase or rebalance\")\n",
    "print(\"\uD83D\uDCA1 Note: With small datasets, Delta may optimize to fewer files than the coalesce number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c366013-4fc4-4e07-b32b-c9d04d2a6039",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Understanding Shuffle Partitions & Adaptive Query Execution:**\n",
    "\n",
    "### Shuffle Partitions\n",
    "When Spark performs wide transformations (joins, aggregations, sorts), it shuffles data across partitions. The number of partitions created during shuffles is controlled by `spark.sql.shuffle.partitions`.\n",
    "\n",
    "**Key considerations:**\n",
    "- Default is often 200 partitions (too many for small datasets)\n",
    "- Best practice: 2-4x your core count for small data\n",
    "- Too many partitions = overhead, too few = underutilization\n",
    "\n",
    "### Adaptive Query Execution (AQE)\n",
    "Databricks serverless compute has AQE automatically enabled. AQE dynamically optimizes queries at runtime by:\n",
    "- **Coalescing shuffle partitions** based on actual data size\n",
    "- **Optimizing join strategies** (broadcast vs shuffle)\n",
    "- **Handling data skew** automatically\n",
    "\n",
    "This means Spark automatically adjusts partition counts for optimal performance, even if you start with a high number!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97fee4cc-c2c3-4463-a46d-e1def437ad05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "# Section 3: De-Duplicating Customer Data\n",
    "\n",
    "**Business Goal:** Marketing reports duplicate customers receiving multiple emails. We need to clean the customer database.\n",
    "\n",
    "In this section, you'll generate synthetic duplicates, attempt simple deduplication, implement case-insensitive matching, standardize data formats, and write optimized output.\n",
    "\n",
    "## Key Concepts:\n",
    "- **dropDuplicates()**: Remove duplicate rows based on column values\n",
    "- **Case-Insensitive Matching**: \"John\" = \"JOHN\" = \"john\"\n",
    "- **Data Standardization**: \"123-45-6789\" = \"123456789\"\n",
    "- **Single File Output**: repartition(1) for consolidated results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8a7e308-62a2-477f-a9c2-d1ebeff89a18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 3.1: Generate Duplicate Customer Dataset\n",
    "\n",
    "Create synthetic duplicates from the base customer data by introducing case variations, spacing differences, and format inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1969dff9-428d-4594-acd6-aea1c6ae7dda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base customers: 300\nGenerated 105,000 customer records (including duplicates)\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# Generate ~103K customer records with duplicates\n",
    "# Use explode() to repeat customers multiple times, then add variations\n",
    "\n",
    "from pyspark.sql.functions import lit, concat, when, upper, lower, expr, explode\n",
    "\n",
    "# Load base customers\n",
    "base_customers_df = spark.table(\"samples.bakehouse.sales_customers\")\n",
    "\n",
    "print(f\"Base customers: {base_customers_df.count()}\")\n",
    "\n",
    "# Create duplicates by repeating each customer ~350 times with variations\n",
    "# Generate an array of 350 elements using sequence(), then explode to create 350 rows per customer\n",
    "duplicates_df = (base_customers_df\n",
    "    .withColumn(\"duplicate_copies\", explode(expr(\"sequence(0, 349)\")))\n",
    "\n",
    "    # Use duplicate_copies as the variation seed\n",
    "    .withColumn(\"duplicate_id\", col(\"duplicate_copies\"))\n",
    "\n",
    "    # Add case variations to first_name\n",
    "    .withColumn(\"first_name\",\n",
    "        when(col(\"duplicate_id\") % 3 == 0, upper(col(\"first_name\")))\n",
    "        .otherwise(col(\"first_name\"))\n",
    "    )\n",
    "\n",
    "    # TODO: Add case variations to last_name\n",
    "    # Use when(col(\"duplicate_id\") % 2 == 0, ...) to uppercase some last names\n",
    "    .withColumn(\"last_name\",\n",
    "        when(col(\"duplicate_id\") % 2 == 0, upper(col(\"last_name\"))).otherwise(col(\"last_name\"))\n",
    "    )\n",
    "\n",
    "    # TODO: Add variations to email (some uppercase domain)\n",
    "    # Use when(col(\"duplicate_id\") % 4 == 0, ...) to uppercase some emails\n",
    "    .withColumn(\"email_address\",\n",
    "        when(col(\"duplicate_id\") % 4 == 0, upper(col(\"email_address\"))).otherwise(col(\"email_address\"))\n",
    "    )\n",
    "\n",
    "    # Drop the temporary column\n",
    "    .drop(\"duplicate_copies\")\n",
    ")\n",
    "\n",
    "# Write to volume\n",
    "(duplicates_df\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .format(\"delta\")\n",
    " .save(f\"{working_dir}/customers_with_duplicates\")\n",
    ")\n",
    "\n",
    "# Check the count\n",
    "dup_count = spark.read.format(\"delta\").load(f\"{working_dir}/customers_with_duplicates\").count()\n",
    "print(f\"Generated {dup_count:,} customer records (including duplicates)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e889dbee-f841-42bc-87bc-7c547bdd7d51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Task 3.1 complete: Generated 105,000 records with duplicates\n"
     ]
    }
   ],
   "source": [
    "# CHECK YOUR WORK\n",
    "assert dup_count > 50000, f\"Should generate significant duplicates, got {dup_count}\"\n",
    "print(f\"✅ Task 3.1 complete: Generated {dup_count:,} records with duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1808e774-fb58-42fb-95b5-290ea6df8913",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 3.2: Simple Deduplication Attempt\n",
    "\n",
    "Try using `dropDuplicates()` on the raw data. Discover that it misses case-sensitive duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a04d5e96-9bd7-40f3-aa96-7e67bd6a005e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 105,000\nAfter simple dedup: 1,800\nRemoved: 103,200 records\n\n⚠️ Still has duplicates due to case sensitivity!\n   'John' != 'JOHN' in simple dropDuplicates\n"
     ]
    }
   ],
   "source": [
    "# Read duplicates\n",
    "dups_df = spark.read.format(\"delta\").load(f\"{working_dir}/customers_with_duplicates\")\n",
    "\n",
    "# TODO: Apply simple deduplication\n",
    "# Use dropDuplicates() on key columns: customerID, first_name, last_name, email_address\n",
    "# Pass columns as a list\n",
    "\n",
    "simple_dedup_df = dups_df.dropDuplicates([\"customerID\", \"first_name\", \"last_name\", \"email_address\"])  # List of column names\n",
    "\n",
    "print(f\"Original: {dups_df.count():,}\")\n",
    "print(f\"After simple dedup: {simple_dedup_df.count():,}\")\n",
    "print(f\"Removed: {dups_df.count() - simple_dedup_df.count():,} records\")\n",
    "print(\"\\n⚠️ Still has duplicates due to case sensitivity!\")\n",
    "print(\"   'John' != 'JOHN' in simple dropDuplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44b80e4a-d446-40f5-b78f-61e4c144c4ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Task 3.2 complete: Simple deduplication attempted\n"
     ]
    }
   ],
   "source": [
    "# CHECK YOUR WORK\n",
    "assert simple_dedup_df.count() < dups_df.count(), \"Should remove some duplicates\"\n",
    "assert simple_dedup_df.count() > 300, \"Should still have many duplicates due to case sensitivity\"\n",
    "print(\"✅ Task 3.2 complete: Simple deduplication attempted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc901417-2dc0-4ebc-b79c-7118c534d497",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 3.3: Case-Insensitive Deduplication\n",
    "\n",
    "Create lowercase versions of text columns and use them for deduplication, then drop the temporary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7b23ad9-fefa-4df9-bfd1-24e243022b50",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Case-insensitive deduplication"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After case-insensitive dedup: 300\nAdditional duplicates removed: 1,500\n"
     ]
    }
   ],
   "source": [
    "# TODO: Case-insensitive deduplication\n",
    "# 1. Create lowercase columns using lower(col(...))\n",
    "# 2. Drop duplicates based on lowercase columns and customerID\n",
    "# 3. Drop temporary lowercase columns\n",
    "\n",
    "from pyspark.sql.functions import lower\n",
    "\n",
    "normalized_df = (dups_df\n",
    "    .withColumn(\"lcFirstName\", lower(col(\"first_name\")))\n",
    "    .withColumn(\"lcLastName\", lower(col(\"last_name\")))\n",
    "    .withColumn(\"lcEmail\", lower(col(\"email_address\")))\n",
    ")\n",
    "\n",
    "# Drop duplicates based on normalized columns and customerID\n",
    "deduped_df = normalized_df.dropDuplicates([\"customerID\", \"lcFirstName\", \"lcLastName\", \"lcEmail\"])\n",
    "\n",
    "# Clean up temporary columns\n",
    "final_df = deduped_df.drop(\"lcFirstName\", \"lcLastName\", \"lcEmail\")\n",
    "\n",
    "print(f\"After case-insensitive dedup: {final_df.count():,}\")\n",
    "print(f\"Additional duplicates removed: {simple_dedup_df.count() - final_df.count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7a3400f-ac1b-4e19-934d-7e68fd2c1261",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Task 3.3 complete: Case-insensitive deduplication successful\n"
     ]
    }
   ],
   "source": [
    "# CHECK YOUR WORK\n",
    "assert final_df.count() < simple_dedup_df.count(), \"Should remove more duplicates than simple method\"\n",
    "assert \"lcFirstName\" not in final_df.columns, \"Should drop temporary columns\"\n",
    "expected_count = 300  # Should be close to base customer count\n",
    "tolerance = 50\n",
    "assert abs(final_df.count() - expected_count) < tolerance, f\"Should have ~{expected_count} unique customers\"\n",
    "print(\"✅ Task 3.3 complete: Case-insensitive deduplication successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43f5f5e7-ab76-42fb-82e8-b0a1dd925a4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 3.4: Data Standardization for Better Matching\n",
    "\n",
    "The Bakehouse customers don't have SSN fields in the actual data, so we'll demonstrate the standardization concept using the postal_zip_code field instead, removing any formatting inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1e299e7-7134-4538-bbbd-3503b27cd3fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After standardization: 300\nFurther improved matching: 0 more duplicates removed\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# Demonstrate standardization concept by creating normalized columns\n",
    "# In a real scenario, you'd standardize phone numbers, SSNs, etc.\n",
    "\n",
    "from pyspark.sql.functions import translate, regexp_replace, trim\n",
    "\n",
    "# For demonstration: normalize postal codes and phone numbers\n",
    "standardized_df = (dups_df\n",
    "    .withColumn(\"lcFirstName\", lower(col(\"first_name\")))\n",
    "    .withColumn(\"lcLastName\", lower(col(\"last_name\")))\n",
    "    .withColumn(\"lcEmail\", lower(col(\"email_address\")))\n",
    "    # Normalize phone numbers (remove dashes, spaces, parentheses)\n",
    "    .withColumn(\"cleanPhone\",\n",
    "        regexp_replace(regexp_replace(col(\"phone_number\"), \"[^0-9]\", \"\"), \" \", \"\"))\n",
    ")\n",
    "\n",
    "# Dedup including standardized fields\n",
    "final_standardized_df = (standardized_df\n",
    "    .dropDuplicates([\n",
    "        \"lcFirstName\", \"lcLastName\", \"lcEmail\",\n",
    "        \"cleanPhone\", \"postal_zip_code\", \"gender\"\n",
    "    ])\n",
    "    .drop(\"lcFirstName\", \"lcLastName\", \"lcEmail\", \"cleanPhone\")\n",
    ")\n",
    "\n",
    "print(f\"After standardization: {final_standardized_df.count():,}\")\n",
    "print(f\"Further improved matching: {final_df.count() - final_standardized_df.count():,} more duplicates removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56718b58-0612-4faf-b969-6d1bc88964ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Task 3.4 complete: Data standardization applied\n\uD83D\uDCDD Standardization catches duplicates with formatting differences\n"
     ]
    }
   ],
   "source": [
    "# CHECK YOUR WORK\n",
    "assert final_standardized_df.count() <= final_df.count(), \"Should not increase count\"\n",
    "print(\"✅ Task 3.4 complete: Data standardization applied\")\n",
    "print(\"\uD83D\uDCDD Standardization catches duplicates with formatting differences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "758a84c0-1acf-4d5f-b64a-1e65dc7b0aac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 3.5: Write Single Partition Output\n",
    "\n",
    "Write the deduplicated data as a single file for downstream systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72ce19bc-6e66-4529-bb1b-c49155f3b0c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files: 1 data file(s)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write to single partition\n",
    "# Use .repartition(1) to create a single output file\n",
    "\n",
    "(final_standardized_df\n",
    " .repartition(1)  # How many partitions for single file?\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .format(\"delta\")\n",
    " .save(f\"{working_dir}/customers_deduplicated\")\n",
    ")\n",
    "\n",
    "# Verify single file\n",
    "output_files = dbutils.fs.ls(f\"{working_dir}/customers_deduplicated\")\n",
    "data_files = [f for f in output_files if f.name.endswith('.parquet')]\n",
    "print(f\"Output files: {len(data_files)} data file(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86703902-9675-4193-9b9d-9713ea8cc591",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Task 3.5 complete: Deduplicated 300 clean customer records\n\uD83D\uDCCA Summary: 105,000 → 300 customers (99.7% duplicates removed)\n"
     ]
    }
   ],
   "source": [
    "# CHECK YOUR WORK\n",
    "deduped_count = spark.read.format(\"delta\").load(f\"{working_dir}/customers_deduplicated\").count()\n",
    "assert deduped_count == final_standardized_df.count(), \"Counts should match\"\n",
    "print(f\"✅ Task 3.5 complete: Deduplicated {deduped_count:,} clean customer records\")\n",
    "print(f\"\uD83D\uDCCA Summary: {dups_df.count():,} → {deduped_count:,} customers ({((1 - deduped_count/dups_df.count()) * 100):.1f}% duplicates removed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9431afc1-b6cf-4af9-97f8-120c2a81ce7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "# Section 4: Comprehensive Performance Challenge\n",
    "\n",
    "**Business Goal:** Build an optimized monthly reporting pipeline that combines all performance techniques.\n",
    "\n",
    "## Requirements:\n",
    "1. Load deduplicated customers\n",
    "2. Join with transactions (optimize join order)\n",
    "3. Join with franchises (filter before join)\n",
    "4. Aggregate metrics by franchise\n",
    "5. Write results with appropriate partitioning\n",
    "\n",
    "Apply everything you've learned: predicate pushdown, filter ordering, and efficient joins!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "876ae79a-dba7-4057-93d1-261f95235741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Challenge: Build Optimized Reporting Pipeline\n",
    "\n",
    "Combine query optimization, partitioning, and clean data into a production-ready pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45e2481e-ece7-45b0-bdf2-7c37041cfc3c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Build optimized reporting pipeline"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>franchiseID</th><th>name</th><th>city</th><th>country</th><th>total_revenue</th><th>transaction_count</th><th>unique_customers</th></tr></thead><tbody><tr><td>3000021</td><td>Butter Bliss</td><td>Honolulu</td><td>US</td><td>2514</td><td>64</td><td>57</td></tr><tr><td>3000002</td><td>Golden Crumbs</td><td>San Francisco</td><td>US</td><td>2502</td><td>76</td><td>69</td></tr><tr><td>3000011</td><td>Butter Babies</td><td>Miami</td><td>US</td><td>1404</td><td>86</td><td>73</td></tr><tr><td>3000030</td><td>Caramel Cravings</td><td>Boston</td><td>US</td><td>1371</td><td>77</td><td>70</td></tr><tr><td>3000032</td><td>Sweet Temptations</td><td>New Orleans</td><td>US</td><td>1368</td><td>83</td><td>76</td></tr><tr><td>3000017</td><td>Crumbly Creations</td><td>Austin</td><td>US</td><td>1356</td><td>76</td><td>68</td></tr><tr><td>3000036</td><td>Sugar High</td><td>Washington D.C.</td><td>US</td><td>1329</td><td>69</td><td>57</td></tr><tr><td>3000005</td><td>Floured Fantasies</td><td>Los Angeles</td><td>US</td><td>1272</td><td>74</td><td>66</td></tr><tr><td>3000028</td><td>Batter Up</td><td>Philadelphia</td><td>US</td><td>1188</td><td>64</td><td>59</td></tr><tr><td>3000034</td><td>Frosted Fantasies</td><td>Las Vegas</td><td>US</td><td>1155</td><td>76</td><td>64</td></tr><tr><td>3000008</td><td>Doughy Dreams</td><td>Chicago</td><td>US</td><td>1101</td><td>69</td><td>66</td></tr><tr><td>3000019</td><td>Dough Dreamers</td><td>Portland</td><td>US</td><td>1083</td><td>63</td><td>57</td></tr><tr><td>3000024</td><td>Flour Power</td><td>Denver</td><td>US</td><td>999</td><td>59</td><td>53</td></tr><tr><td>3000038</td><td>Dough Delights</td><td>Seattle</td><td>US</td><td>942</td><td>54</td><td>51</td></tr><tr><td>3000026</td><td>Crumble Delights</td><td>Nashville</td><td>US</td><td>927</td><td>59</td><td>52</td></tr><tr><td>3000014</td><td>Sweet Temptations</td><td>Seattle</td><td>US</td><td>225</td><td>75</td><td>72</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3000021,
         "Butter Bliss",
         "Honolulu",
         "US",
         2514,
         64,
         57
        ],
        [
         3000002,
         "Golden Crumbs",
         "San Francisco",
         "US",
         2502,
         76,
         69
        ],
        [
         3000011,
         "Butter Babies",
         "Miami",
         "US",
         1404,
         86,
         73
        ],
        [
         3000030,
         "Caramel Cravings",
         "Boston",
         "US",
         1371,
         77,
         70
        ],
        [
         3000032,
         "Sweet Temptations",
         "New Orleans",
         "US",
         1368,
         83,
         76
        ],
        [
         3000017,
         "Crumbly Creations",
         "Austin",
         "US",
         1356,
         76,
         68
        ],
        [
         3000036,
         "Sugar High",
         "Washington D.C.",
         "US",
         1329,
         69,
         57
        ],
        [
         3000005,
         "Floured Fantasies",
         "Los Angeles",
         "US",
         1272,
         74,
         66
        ],
        [
         3000028,
         "Batter Up",
         "Philadelphia",
         "US",
         1188,
         64,
         59
        ],
        [
         3000034,
         "Frosted Fantasies",
         "Las Vegas",
         "US",
         1155,
         76,
         64
        ],
        [
         3000008,
         "Doughy Dreams",
         "Chicago",
         "US",
         1101,
         69,
         66
        ],
        [
         3000019,
         "Dough Dreamers",
         "Portland",
         "US",
         1083,
         63,
         57
        ],
        [
         3000024,
         "Flour Power",
         "Denver",
         "US",
         999,
         59,
         53
        ],
        [
         3000038,
         "Dough Delights",
         "Seattle",
         "US",
         942,
         54,
         51
        ],
        [
         3000026,
         "Crumble Delights",
         "Nashville",
         "US",
         927,
         59,
         52
        ],
        [
         3000014,
         "Sweet Temptations",
         "Seattle",
         "US",
         225,
         75,
         72
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "franchiseID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "total_revenue",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "transaction_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "unique_customers",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Build optimized reporting pipeline\n",
    "# Apply all performance techniques learned:\n",
    "# - Load deduplicated data\n",
    "# - Filter before joining (predicate pushdown)\n",
    "# - Proper join order\n",
    "\n",
    "from pyspark.sql.functions import sum, count, countDistinct, desc, upper, trim\n",
    "\n",
    "# Step 1: Load deduplicated customers from f\"{working_dir}/customers_deduplicated\"\n",
    "clean_customers_df = spark.read.format(\"delta\").load(f\"{working_dir}/customers_deduplicated\") \n",
    "\n",
    "# Step 2: Load and filter franchises to US only (predicate pushdown!) \n",
    "usa_franchises_df = spark.table(\"samples.bakehouse.sales_franchises\").filter(col(\"country\") == \"US\")\n",
    "\n",
    "# Step 3: Join transactions with clean customers, then with USA franchises\n",
    "# Use \"customerID\" for customer join, \"franchiseID\" for franchise join\n",
    "enriched_transactions_df = (transactions_df\n",
    "    .join(clean_customers_df, \"customerID\")  \n",
    "    .join( usa_franchises_df  , \"franchiseID\")\n",
    ")\n",
    "\n",
    "# Step 4: Calculate franchise performance metrics\n",
    "# Note: After joining multiple tables, some columns (name, city, country) exist in both\n",
    "# customers and franchises DataFrames. You must disambiguate these columns using\n",
    "# the DataFrame reference syntax: usa_franchises_df[\"column_name\"]\n",
    "franchise_report_df = (enriched_transactions_df\n",
    "    .groupBy(\n",
    "        \"franchiseID\",\n",
    "        usa_franchises_df[\"name\"],  # Disambiguate franchise name\n",
    "        usa_franchises_df[\"city\"],  # Disambiguate franchise city\n",
    "        usa_franchises_df[\"country\"]  # Disambiguate franchise country\n",
    "    )\n",
    "    .agg(\n",
    "        sum(\"totalPrice\").alias(\"total_revenue\"),\n",
    "        count(\"transactionID\").alias(\"transaction_count\"),\n",
    "        countDistinct(\"customerID\").alias(\"unique_customers\")\n",
    "    )\n",
    "    .orderBy(desc(\"total_revenue\"))\n",
    ")\n",
    "\n",
    "display(franchise_report_df)\n",
    "\n",
    "# Step 5: Write optimized output\n",
    "(franchise_report_df\n",
    " .repartition(1)   # How many partitions for single file?\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .format(\"delta\")\n",
    " .save(f\"{working_dir}/franchise_performance_report\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2334731-400d-488e-b305-0695f1da6117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Challenge complete: Generated report for 16 USA franchises\n\uD83C\uDF89 Congratulations! You've mastered Spark performance optimization!\n"
     ]
    }
   ],
   "source": [
    "# CHECK YOUR WORK\n",
    "report_df = spark.read.format(\"delta\").load(f\"{working_dir}/franchise_performance_report\")\n",
    "assert report_df.count() > 0, \"Should have franchise performance data\"\n",
    "assert \"franchiseID\" in report_df.columns, \"Should include franchiseID\"\n",
    "print(f\"✅ Challenge complete: Generated report for {report_df.count()} USA franchises\")\n",
    "print(\"\uD83C\uDF89 Congratulations! You've mastered Spark performance optimization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad0855a2-0b81-4ae0-a7e1-030d22623f31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "# Cleanup\n",
    "\n",
    "Run the following cell to clean up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3e96407-d40b-493f-9320-4f2675288860",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned up working directory: /Volumes/bakehouse_catalog/performance_lab/workspace\n"
     ]
    }
   ],
   "source": [
    "# Clean up working directory\n",
    "dbutils.fs.rm(f\"{working_dir}/transactions_partitioned\", recurse=True)\n",
    "dbutils.fs.rm(f\"{working_dir}/repartitioned_demo\", recurse=True)\n",
    "dbutils.fs.rm(f\"{working_dir}/coalesced_demo\", recurse=True)\n",
    "dbutils.fs.rm(f\"{working_dir}/customers_with_duplicates\", recurse=True)\n",
    "dbutils.fs.rm(f\"{working_dir}/customers_deduplicated\", recurse=True)\n",
    "dbutils.fs.rm(f\"{working_dir}/franchise_performance_report\", recurse=True)\n",
    "print(f\"✅ Cleaned up working directory: {working_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0241e9d5-e332-48bd-84ea-be06dbadb0fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Congratulations!\n",
    "\n",
    "You've completed the comprehensive Bakehouse Performance Optimization lab, covering:\n",
    "\n",
    "✅ **Query Optimization** - Catalyst optimizer, explain plans, predicate pushdown, join optimization\n",
    "✅ **Partitioning** - repartition vs coalesce, shuffle configuration, AQE\n",
    "✅ **De-Duplication** - Case-insensitive matching, data standardization, efficient output\n",
    "✅ **Integration** - Combined techniques in production pipeline\n",
    "\n",
    "## Key Takeaways:\n",
    "\n",
    "1. **Always check explain plans** - Understand what Spark is actually doing\n",
    "2. **Filter early, filter often** - Push predicates close to data sources\n",
    "3. **Partition wisely** - Balance parallelism with overhead\n",
    "4. **Match data size to method** - Small data different from big data\n",
    "5. **Standardize before deduplication** - Clean data improves matching\n",
    "\n",
    "These performance optimization skills are essential for building scalable, production-ready data pipelines!"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8924960131851846,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "0.2 - Spark Optimization",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}